# Here you can define credentials for different data sets and environment.

# Here you can define training and inference configuration for training and inference pipeline.

# Example:
train_percentage = 0.8
contamination_rate = 0.02
ann_anomaly_class = 1
har_anomaly_class = 3
cov_anomaly_class = 6

batch_size = 32
num_steps_per_iteration = 2000
log_interval = 1
num_test_trajectories = 1
max_iteration = 10
init_epsilon = 1
final_epsilon = 0.1
save_model_interval = 100
start_timestep = 2000
max_buffer_size = 100000

# dqn_agent
device = "cpu"
update_target_network_interval = 10000
gamma = 0.99
tau = 0.5
n = 1
learning_rate = 0.0003
momentum = 0.95
hidden_dims = [16]

# environment.py
sample_num = 100
p = 0.5


[INFERENCE]
MODEL_DIR = "/models/dummy.p"
OUTPUT_DIR = "/data/output/inference.csv"
# test1 = [1,2,3,4,5]
# test2 = {k = "v",name = "dw"}



